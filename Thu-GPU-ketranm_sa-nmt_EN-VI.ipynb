{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Thu-GPU-ketranm_sa-nmt.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WJ0h9EUrHyVI","colab_type":"text"},"source":["To run this notebook, follow the steps below.\n","\n","1. cd to Code/sa-nmt diretcory\n","\n","2. train first, don't clear the output, watch for BLEU score (appears every 5000 steps) and acc (accuracy)\n","\n","3. when file model_best.pt appears in sa-nmt/ folder (every 5000 train steps), we can use it to translate\n","\n","4. translate by\n","  \n","  4.1 create a source sentences, write it in file input.txt (cell has %% writefile input.txt)\n","  \n","  4.2 run translate command in the cell\n","  \n","  4.3 see result by viewing file trans.bpe (cell has %pycat trans.bpe)\n","\n","NOTE: if path error occurs, Restart Runtime and do again from cell 1"]},{"cell_type":"code","metadata":{"id":"_qUmvlahZmq-","colab_type":"code","outputId":"5b4764dd-eb60-4b2b-fffb-408f991d8bbb","executionInfo":{"status":"ok","timestamp":1581928758734,"user_tz":-420,"elapsed":25754,"user":{"displayName":"Thư Trần Thị Anh","photoUrl":"","userId":"06893536815286384763"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# step 1\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lp29ktj4O10M","colab_type":"code","colab":{}},"source":["# step 2.a:\n","# Thu:\n","import os\n","os.chdir(\"drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJrICHBqO7z8","colab_type":"code","colab":{}},"source":["# step 2.b:\n","# Trinh: ENG-VN\n","# import os\n","# os.chdir(\"drive/My Drive/NLP/Code/sa-nmt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMu63VE9EJKG","colab_type":"code","colab":{}},"source":["# step 2.c:\n","# Phuc: VN-ENG\n","# import os\n","# os.chdir(\"drive/My Drive/nlp_gpu_sa_nmt/Code/sa-nmt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"irn9N08-QsZI","colab_type":"code","outputId":"86f13ffe-6ed1-4fb0-c9b7-16fadce83fa9","executionInfo":{"status":"ok","timestamp":1578532905064,"user_tz":-420,"elapsed":10454,"user":{"displayName":"Thư Trần Thị Anh","photoUrl":"","userId":"06893536815286384763"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!pwd\n","!ls\n","!python -V"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt\n","archive\t\t input.txt\t     Loss.py\t    onmt\t run.sh\n","attention.py\t _ipynb_checkpoints  model_best.pt  onmt.zip\t train.py\n","data\t\t Iterator.py\t     model.bpe\t    opts.py\t trans.bpe\n","extract_tree.py  iwslt\t\t     models.py\t    __pycache__  translate.py\n","infer.py\t iwslt0\t\t     model.txt\t    README.md\t Utils.py\n","Python 3.6.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmXO-JzgmI12","colab_type":"code","outputId":"ca68e6f6-b6b3-4de9-b824-bdec6780814e","executionInfo":{"status":"ok","timestamp":1577161684012,"user_tz":-420,"elapsed":10804,"user":{"displayName":"Trinh Ngô Lê Phương","photoUrl":"","userId":"02695284126918454094"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["!nvidia-smi\n","!nvcc --version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Dec 24 04:27:59 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vEuUzWK52mim","colab_type":"code","colab":{}},"source":["# !!python train.py -datasets iwslt/train.en-de.de.tok.bpe iwslt/train.en-de.en.tok.bpe -valid_datasets iwslt/tst2015.en-de.de.tok.bpe iwslt/tst2015.en-de.en.tok.bpe -dicts iwslt/train.en-de.de.tok.bpe.pkl iwslt/train.en-de.en.tok.bpe.pkl -share_decoder_embeddings -word_vec_size 32 -rnn_size 32 -encoder_type sabrnn -encode_multi_key -share_attn -report_every 100 -learning_rate 0.001 -eval_every 5000 -epochs 13 -batch_size 64 -max_updates 1000000 -gpuid 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ulv_Dj_KErTw","colab_type":"text"},"source":["TRAIN, need to keep colab running continuously long until reaching iteration 1 mil/1 mil. \n","Google Colab will disconnect sooner, but it's ok, try to keep it running as long as possible\n","# **TRAIN: ENG-VN**"]},{"cell_type":"markdown","metadata":{"id":"yXs3fA6oyO8i","colab_type":"text"},"source":[" -train_from model_best.pt"]},{"cell_type":"code","metadata":{"id":"q3ZnqY5MkSmH","colab_type":"code","outputId":"00181d45-b877-46c1-e93a-7dd941576217","executionInfo":{"status":"ok","timestamp":1581962760410,"user_tz":-420,"elapsed":5504245,"user":{"displayName":"Thư Trần Thị Anh","photoUrl":"","userId":"06893536815286384763"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py -datasets iwslt/train.en.bpe iwslt/train.vi.bpe -valid_datasets iwslt/test2015.en.bpe iwslt/test2015.vi.bpe -dicts iwslt/all.en.bpe.pkl iwslt/all.vi.bpe.pkl -share_decoder_embeddings -word_vec_size 1024 -rnn_size 1024 -encoder_type sabrnn -encode_multi_key -share_attn -report_every 100 -learning_rate 0.001 -eval_every 1000 -epochs 13 -batch_size 32 -max_updates 1000000 -gpuid 0 -layers 4 -dropout 0.5 -train_from model_best.pt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=32, beam_size=12, datasets=['iwslt/train.en.bpe', 'iwslt/train.vi.bpe'], decoder_type='rnn', dicts=['iwslt/all.en.bpe.pkl', 'iwslt/all.vi.bpe.pkl'], dropout=0.5, encode_multi_key=True, encoder_type='sabrnn', epochs=13, eval_every=1000, gpuid=[0], hard=False, input_feed=1, layers=4, learning_rate=0.001, learning_rate_decay=0.5, max_decay_step=5, max_generator_batches=32, max_grad_norm=5, max_seq_length=100, max_thres=7.0, max_updates=1000000, min_thres=-5.0, optim='adam', param_init=0.1, report_every=100, rnn_size=1024, rnn_type='LSTM', save_model='model', seed=42, share_attn=True, share_decoder_embeddings=True, shuffle=1, src_vocab_size=-1, start_checkpoint_at=0, start_epoch=1, start_eval_checkpoint_at=0, tgt_vocab_size=-1, train_from='model_best.pt', valid_datasets=['iwslt/test2015.en.bpe', 'iwslt/test2015.vi.bpe'], word_vec_size=1024)\n","| build data iterators\n","shuffle iwslt/train.en.bpe | iwslt/train.vi.bpe\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","| vocabulary size. source = 9973; target = 9759\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","| Load trained model!\n","Loading model\n","Add punctuation constrain!\n","NMT(\n","  (encoder): SAEncoder(\n","    (embeddings): Embedding(9973, 1024, padding_idx=0)\n","    (rnn): LSTM(1024, 512, num_layers=4, dropout=0.5, bidirectional=True)\n","    (tree_attn): TreeAttention(\n","      (q): Linear(in_features=1024, out_features=1024, bias=False)\n","      (k): Linear(in_features=1024, out_features=1024, bias=False)\n","      (v): Linear(in_features=1024, out_features=1024, bias=False)\n","      (dtree): MatrixTree()\n","    )\n","  )\n","  (decoder): Decoder(\n","    (embeddings): Embedding(9759, 1024, padding_idx=0)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.5, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(2048, 1024)\n","        (1): LSTMCell(1024, 1024)\n","        (2): LSTMCell(1024, 1024)\n","        (3): LSTMCell(1024, 1024)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_in): Linear(in_features=1024, out_features=1024, bias=False)\n","      (linear_out): Linear(in_features=3072, out_features=1024, bias=False)\n","      (gate): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=1024, out_features=9759, bias=True)\n","    (1): LogSoftmax()\n","  )\n",")\n","* number of parameters: 91586079\n","encoder:  38557696\n","decoder:  53028383\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","170415.8337779045 83446\n","Epoch  1,   100/1000000; acc:  57.87; ppl:   7.71; 2121 tgt tok/s;     39 s elapsed\n","169824.3419342041 80761\n","Epoch  1,   200/1000000; acc:  56.73; ppl:   8.19; 2091 tgt tok/s;     78 s elapsed\n","178532.20876598358 82395\n","Epoch  1,   300/1000000; acc:  56.17; ppl:   8.73; 2091 tgt tok/s;    117 s elapsed\n","180527.3847784996 82331\n","Epoch  1,   400/1000000; acc:  55.66; ppl:   8.96; 2105 tgt tok/s;    156 s elapsed\n","183629.77834653854 82197\n","Epoch  1,   500/1000000; acc:  55.12; ppl:   9.34; 2104 tgt tok/s;    196 s elapsed\n","181807.65361642838 81981\n","Epoch  1,   600/1000000; acc:  55.38; ppl:   9.19; 2103 tgt tok/s;    235 s elapsed\n","184572.98819971085 82127\n","Epoch  1,   700/1000000; acc:  54.94; ppl:   9.46; 2101 tgt tok/s;    274 s elapsed\n","183586.09609651566 82200\n","Epoch  1,   800/1000000; acc:  55.40; ppl:   9.33; 2127 tgt tok/s;    312 s elapsed\n","188193.98820972443 83306\n","Epoch  1,   900/1000000; acc:  54.72; ppl:   9.57; 2128 tgt tok/s;    351 s elapsed\n","187336.55136442184 82280\n","Epoch  1,  1000/1000000; acc:  54.57; ppl:   9.75; 2131 tgt tok/s;    390 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","69036.34954833984 25351\n","69036.34954833984 25351\n","Validation perplexity 1000: 15.2293\n","Learning rate: 0.001\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:37: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  volatile=True)\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  init_target = Variable(init_target, volatile=True)\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:115: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  init_target = Variable(next_ys.view(1, -1), volatile=True)\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 24.89, 58.2/32.8/19.9/12.5 (BP=0.948, ratio=0.949, hyp_len=24895, ref_len=26235)\n","\n","Validation BLEU 1000: 24.89\n","Saved model: 1000 | BLEU 24.89\n","183639.40210437775 81801\n","Epoch  1,  1100/1000000; acc:  54.90; ppl:   9.44; 490 tgt tok/s;    557 s elapsed\n","182864.6774969101 81180\n","Epoch  1,  1200/1000000; acc:  54.96; ppl:   9.51; 2086 tgt tok/s;    596 s elapsed\n","184686.08228445053 81087\n","Epoch  1,  1300/1000000; acc:  54.64; ppl:   9.75; 2103 tgt tok/s;    634 s elapsed\n","183297.172870636 80890\n","Epoch  1,  1400/1000000; acc:  54.74; ppl:   9.64; 2100 tgt tok/s;    673 s elapsed\n","186002.34064865112 82017\n","Epoch  1,  1500/1000000; acc:  54.85; ppl:   9.66; 2126 tgt tok/s;    712 s elapsed\n","185951.32966804504 82191\n","Epoch  1,  1600/1000000; acc:  54.72; ppl:   9.61; 2126 tgt tok/s;    750 s elapsed\n","186564.6804471016 81613\n","Epoch  1,  1700/1000000; acc:  54.45; ppl:   9.84; 2107 tgt tok/s;    789 s elapsed\n","183349.2744884491 80866\n","Epoch  1,  1800/1000000; acc:  54.77; ppl:   9.65; 2111 tgt tok/s;    827 s elapsed\n","183081.12688732147 81194\n","Epoch  1,  1900/1000000; acc:  55.07; ppl:   9.53; 2104 tgt tok/s;    866 s elapsed\n","187716.85223770142 82962\n","Epoch  1,  2000/1000000; acc:  54.93; ppl:   9.61; 2134 tgt tok/s;    905 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","69327.02374267578 25351\n","69327.02374267578 25351\n","Validation perplexity 2000: 15.4049\n","Learning rate: 0.0005\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 25.34, 57.0/32.2/19.5/12.3 (BP=0.983, ratio=0.984, hyp_len=25803, ref_len=26235)\n","\n","Validation BLEU 2000: 25.34\n","Saved model: 2000 | BLEU 25.34\n","182791.02267169952 81106\n","Epoch  1,  2100/1000000; acc:  55.09; ppl:   9.52; 491 tgt tok/s;   1070 s elapsed\n","179400.19641256332 81595\n","Epoch  1,  2200/1000000; acc:  55.87; ppl:   9.01; 2141 tgt tok/s;   1108 s elapsed\n","175654.06577777863 80535\n","Epoch  1,  2300/1000000; acc:  56.21; ppl:   8.86; 2108 tgt tok/s;   1146 s elapsed\n","177441.3041496277 81559\n","Epoch  1,  2400/1000000; acc:  55.95; ppl:   8.81; 2122 tgt tok/s;   1185 s elapsed\n","182536.80536460876 83579\n","Epoch  1,  2500/1000000; acc:  55.98; ppl:   8.88; 2151 tgt tok/s;   1223 s elapsed\n","177155.25677013397 80411\n","Epoch  1,  2600/1000000; acc:  55.87; ppl:   9.05; 2108 tgt tok/s;   1262 s elapsed\n","177655.44836902618 81336\n","Epoch  1,  2700/1000000; acc:  56.02; ppl:   8.88; 2119 tgt tok/s;   1300 s elapsed\n","178706.32061195374 82683\n","Epoch  1,  2800/1000000; acc:  56.24; ppl:   8.68; 2145 tgt tok/s;   1338 s elapsed\n","176067.64464378357 82151\n","Epoch  1,  2900/1000000; acc:  56.64; ppl:   8.53; 2126 tgt tok/s;   1377 s elapsed\n","178932.11431837082 82879\n","Epoch  1,  3000/1000000; acc:  56.13; ppl:   8.66; 2148 tgt tok/s;   1416 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","66993.50408935547 25351\n","66993.50408935547 25351\n","Validation perplexity 3000: 14.0502\n","Learning rate: 0.0005\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 25.54, 58.7/33.3/20.1/12.8 (BP=0.959, ratio=0.960, hyp_len=25176, ref_len=26235)\n","\n","Validation BLEU 3000: 25.54\n","Saved model: 3000 | BLEU 25.54\n","176172.46527147293 82149\n","Epoch  1,  3100/1000000; acc:  56.51; ppl:   8.54; 503 tgt tok/s;   1579 s elapsed\n","176250.82938194275 81073\n","Epoch  1,  3200/1000000; acc:  56.30; ppl:   8.79; 2120 tgt tok/s;   1617 s elapsed\n","175332.52182722092 82513\n","Epoch  1,  3300/1000000; acc:  56.89; ppl:   8.37; 2147 tgt tok/s;   1656 s elapsed\n","174036.52950429916 80753\n","Epoch  1,  3400/1000000; acc:  56.42; ppl:   8.63; 2115 tgt tok/s;   1694 s elapsed\n","181323.4924840927 83722\n","Epoch  1,  3500/1000000; acc:  56.32; ppl:   8.72; 2154 tgt tok/s;   1733 s elapsed\n","shuffle iwslt/train.en.bpe | iwslt/train.vi.bpe\n","93584.91655874252 45711\n","Epoch  2,  3600/1000000; acc:  57.59; ppl:   7.75; 2195 tgt tok/s;     21 s elapsed\n","159917.67789936066 81162\n","Epoch  2,  3700/1000000; acc:  58.76; ppl:   7.17; 2109 tgt tok/s;     59 s elapsed\n","163233.04761266708 83047\n","Epoch  2,  3800/1000000; acc:  59.07; ppl:   7.14; 2141 tgt tok/s;     98 s elapsed\n","161824.31391334534 81940\n","Epoch  2,  3900/1000000; acc:  58.81; ppl:   7.21; 2146 tgt tok/s;    136 s elapsed\n","162280.8870959282 81657\n","Epoch  2,  4000/1000000; acc:  58.59; ppl:   7.30; 2126 tgt tok/s;    175 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","67407.67138671875 25351\n","67407.67138671875 25351\n","Validation perplexity 4000: 14.2816\n","Learning rate: 0.00025\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.21, 57.9/33.1/20.2/12.9 (BP=0.987, ratio=0.987, hyp_len=25885, ref_len=26235)\n","\n","Validation BLEU 4000: 26.21\n","Saved model: 4000 | BLEU 26.21\n","161638.1927843094 81659\n","Epoch  2,  4100/1000000; acc:  58.84; ppl:   7.24; 498 tgt tok/s;    339 s elapsed\n","159201.5768251419 81225\n","Epoch  2,  4200/1000000; acc:  58.96; ppl:   7.10; 2116 tgt tok/s;    377 s elapsed\n","159723.34312582016 80722\n","Epoch  2,  4300/1000000; acc:  58.90; ppl:   7.23; 2113 tgt tok/s;    415 s elapsed\n","161538.94432592392 82454\n","Epoch  2,  4400/1000000; acc:  59.00; ppl:   7.09; 2143 tgt tok/s;    454 s elapsed\n","161726.5748281479 82676\n","Epoch  2,  4500/1000000; acc:  59.16; ppl:   7.07; 2138 tgt tok/s;    492 s elapsed\n","159576.3863902092 81517\n","Epoch  2,  4600/1000000; acc:  59.19; ppl:   7.08; 2133 tgt tok/s;    531 s elapsed\n","156844.98327445984 80633\n","Epoch  2,  4700/1000000; acc:  59.27; ppl:   6.99; 2120 tgt tok/s;    569 s elapsed\n","161798.18809843063 83228\n","Epoch  2,  4800/1000000; acc:  59.41; ppl:   6.99; 2152 tgt tok/s;    607 s elapsed\n","160815.35029125214 82533\n","Epoch  2,  4900/1000000; acc:  59.23; ppl:   7.02; 2151 tgt tok/s;    646 s elapsed\n","159470.107609272 81760\n","Epoch  2,  5000/1000000; acc:  59.28; ppl:   7.03; 2137 tgt tok/s;    684 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","66907.43176269531 25351\n","66907.43176269531 25351\n","Validation perplexity 5000: 14.0026\n","Learning rate: 0.00025\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.34, 58.9/33.9/20.7/13.2 (BP=0.969, ratio=0.970, hyp_len=25441, ref_len=26235)\n","\n","Validation BLEU 5000: 26.34\n","Saved model: 5000 | BLEU 26.34\n","158429.50817203522 82900\n","Epoch  2,  5100/1000000; acc:  60.03; ppl:   6.76; 509 tgt tok/s;    847 s elapsed\n","157047.47423267365 81091\n","Epoch  2,  5200/1000000; acc:  59.71; ppl:   6.94; 2128 tgt tok/s;    885 s elapsed\n","158568.83571577072 81291\n","Epoch  2,  5300/1000000; acc:  59.34; ppl:   7.03; 2134 tgt tok/s;    923 s elapsed\n","153385.86084222794 80800\n","Epoch  2,  5400/1000000; acc:  60.03; ppl:   6.67; 2118 tgt tok/s;    961 s elapsed\n","152424.61363363266 79766\n","Epoch  2,  5500/1000000; acc:  60.07; ppl:   6.76; 2089 tgt tok/s;    999 s elapsed\n","159937.53042936325 82271\n","Epoch  2,  5600/1000000; acc:  59.30; ppl:   6.99; 2141 tgt tok/s;   1038 s elapsed\n","155161.83082199097 80527\n","Epoch  2,  5700/1000000; acc:  59.87; ppl:   6.87; 2120 tgt tok/s;   1076 s elapsed\n","159568.50320148468 82890\n","Epoch  2,  5800/1000000; acc:  59.73; ppl:   6.86; 2153 tgt tok/s;   1114 s elapsed\n","155993.0143828392 81231\n","Epoch  2,  5900/1000000; acc:  59.65; ppl:   6.82; 2133 tgt tok/s;   1152 s elapsed\n","156714.98305559158 81683\n","Epoch  2,  6000/1000000; acc:  59.93; ppl:   6.81; 2139 tgt tok/s;   1190 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","66724.14666748047 25351\n","66724.14666748047 25351\n","Validation perplexity 6000: 13.9017\n","Learning rate: 0.00025\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.36, 58.6/33.6/20.5/13.1 (BP=0.977, ratio=0.977, hyp_len=25640, ref_len=26235)\n","\n","Validation BLEU 6000: 26.36\n","Saved model: 6000 | BLEU 26.36\n","158983.35009145737 81978\n","Epoch  2,  6100/1000000; acc:  59.68; ppl:   6.95; 501 tgt tok/s;   1354 s elapsed\n","160876.119389534 82823\n","Epoch  2,  6200/1000000; acc:  59.51; ppl:   6.98; 2158 tgt tok/s;   1392 s elapsed\n","157205.0086402893 81943\n","Epoch  2,  6300/1000000; acc:  60.04; ppl:   6.81; 2151 tgt tok/s;   1430 s elapsed\n","157660.08350086212 82535\n","Epoch  2,  6400/1000000; acc:  59.77; ppl:   6.75; 2140 tgt tok/s;   1469 s elapsed\n","153812.67210578918 80690\n","Epoch  2,  6500/1000000; acc:  60.00; ppl:   6.73; 2127 tgt tok/s;   1507 s elapsed\n","158910.7799692154 82354\n","Epoch  2,  6600/1000000; acc:  59.48; ppl:   6.89; 2138 tgt tok/s;   1545 s elapsed\n","157580.5839061737 82653\n","Epoch  2,  6700/1000000; acc:  60.00; ppl:   6.73; 2156 tgt tok/s;   1584 s elapsed\n","158780.31195259094 82300\n","Epoch  2,  6800/1000000; acc:  59.99; ppl:   6.88; 2134 tgt tok/s;   1622 s elapsed\n","158746.65807247162 82250\n","Epoch  2,  6900/1000000; acc:  59.56; ppl:   6.89; 2095 tgt tok/s;   1662 s elapsed\n","161472.55769586563 82951\n","Epoch  2,  7000/1000000; acc:  59.45; ppl:   7.00; 2146 tgt tok/s;   1700 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","66461.37518310547 25351\n","66461.37518310547 25351\n","Validation perplexity 7000: 13.7584\n","Learning rate: 0.00025\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.31, 59.0/34.0/20.7/13.2 (BP=0.967, ratio=0.967, hyp_len=25377, ref_len=26235)\n","\n","Validation BLEU 7000: 26.31\n","shuffle iwslt/train.en.bpe | iwslt/train.vi.bpe\n","14526.359735488892 6685\n","Epoch  3,  7100/1000000; acc:  55.36; ppl:   8.78; 2768 tgt tok/s;      2 s elapsed\n","146077.08247089386 81094\n","Epoch  3,  7200/1000000; acc:  61.66; ppl:   6.06; 2115 tgt tok/s;     41 s elapsed\n","148327.1763496399 81131\n","Epoch  3,  7300/1000000; acc:  61.18; ppl:   6.22; 2134 tgt tok/s;     79 s elapsed\n","151206.9431886673 82392\n","Epoch  3,  7400/1000000; acc:  61.18; ppl:   6.27; 2145 tgt tok/s;    117 s elapsed\n","152851.65384578705 82596\n","Epoch  3,  7500/1000000; acc:  61.05; ppl:   6.36; 2152 tgt tok/s;    156 s elapsed\n","153323.05486631393 82921\n","Epoch  3,  7600/1000000; acc:  60.80; ppl:   6.35; 2152 tgt tok/s;    194 s elapsed\n","150443.48418712616 82369\n","Epoch  3,  7700/1000000; acc:  61.26; ppl:   6.21; 2147 tgt tok/s;    232 s elapsed\n","150159.66339969635 82507\n","Epoch  3,  7800/1000000; acc:  61.31; ppl:   6.17; 2153 tgt tok/s;    271 s elapsed\n","149080.38999176025 81712\n","Epoch  3,  7900/1000000; acc:  61.34; ppl:   6.20; 2146 tgt tok/s;    309 s elapsed\n","149632.40321922302 81153\n","Epoch  3,  8000/1000000; acc:  61.04; ppl:   6.32; 2123 tgt tok/s;    347 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","67204.91235351562 25351\n","67204.91235351562 25351\n","Validation perplexity 8000: 14.1679\n","Learning rate: 0.000125\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.34, 58.5/33.7/20.6/13.0 (BP=0.978, ratio=0.978, hyp_len=25653, ref_len=26235)\n","\n","Validation BLEU 8000: 26.34\n","152091.63731765747 82738\n","Epoch  3,  8100/1000000; acc:  61.02; ppl:   6.29; 512 tgt tok/s;    509 s elapsed\n","152093.813226223 83257\n","Epoch  3,  8200/1000000; acc:  61.06; ppl:   6.21; 2164 tgt tok/s;    547 s elapsed\n","149484.20436429977 81552\n","Epoch  3,  8300/1000000; acc:  61.15; ppl:   6.25; 2129 tgt tok/s;    586 s elapsed\n","147478.17625808716 81499\n","Epoch  3,  8400/1000000; acc:  61.65; ppl:   6.11; 2129 tgt tok/s;    624 s elapsed\n","145645.83480596542 80265\n","Epoch  3,  8500/1000000; acc:  61.51; ppl:   6.14; 2115 tgt tok/s;    662 s elapsed\n","146609.60587215424 81006\n","Epoch  3,  8600/1000000; acc:  61.44; ppl:   6.11; 2126 tgt tok/s;    700 s elapsed\n","149696.44103622437 82422\n","Epoch  3,  8700/1000000; acc:  61.31; ppl:   6.15; 2150 tgt tok/s;    738 s elapsed\n","149111.05565166473 81702\n","Epoch  3,  8800/1000000; acc:  61.24; ppl:   6.20; 2136 tgt tok/s;    777 s elapsed\n","155422.86732244492 84824\n","Epoch  3,  8900/1000000; acc:  61.28; ppl:   6.25; 2175 tgt tok/s;    816 s elapsed\n","142401.22861528397 79645\n","Epoch  3,  9000/1000000; acc:  61.77; ppl:   5.98; 2109 tgt tok/s;    853 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","67139.78457641602 25351\n","67139.78457641602 25351\n","Validation perplexity 9000: 14.1315\n","Learning rate: 6.25e-05\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.64, 59.2/34.1/20.8/13.3 (BP=0.974, ratio=0.974, hyp_len=25552, ref_len=26235)\n","\n","Validation BLEU 9000: 26.64\n","Saved model: 9000 | BLEU 26.64\n","146094.5729060173 81663\n","Epoch  3,  9100/1000000; acc:  61.87; ppl:   5.98; 501 tgt tok/s;   1016 s elapsed\n","144806.36702537537 80753\n","Epoch  3,  9200/1000000; acc:  61.71; ppl:   6.01; 2129 tgt tok/s;   1054 s elapsed\n","148150.09015321732 81519\n","Epoch  3,  9300/1000000; acc:  61.39; ppl:   6.16; 2140 tgt tok/s;   1092 s elapsed\n","152536.77265262604 83539\n","Epoch  3,  9400/1000000; acc:  61.49; ppl:   6.21; 2163 tgt tok/s;   1131 s elapsed\n","148653.83527946472 82087\n","Epoch  3,  9500/1000000; acc:  61.42; ppl:   6.12; 2142 tgt tok/s;   1169 s elapsed\n","147858.50535345078 82196\n","Epoch  3,  9600/1000000; acc:  61.65; ppl:   6.04; 2157 tgt tok/s;   1208 s elapsed\n","146291.58401679993 81677\n","Epoch  3,  9700/1000000; acc:  61.86; ppl:   6.00; 2134 tgt tok/s;   1246 s elapsed\n","148612.52739715576 81989\n","Epoch  3,  9800/1000000; acc:  61.60; ppl:   6.13; 2136 tgt tok/s;   1284 s elapsed\n","149930.31348085403 83015\n","Epoch  3,  9900/1000000; acc:  61.76; ppl:   6.09; 2162 tgt tok/s;   1323 s elapsed\n","142499.0739068985 80813\n","Epoch  3, 10000/1000000; acc:  62.34; ppl:   5.83; 2128 tgt tok/s;   1361 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","66767.08145141602 25351\n","66767.08145141602 25351\n","Validation perplexity 10000: 13.9253\n","Learning rate: 3.125e-05\n","It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n","MY_BLEU BLEU = 26.87, 59.2/34.3/21.1/13.6 (BP=0.973, ratio=0.973, hyp_len=25537, ref_len=26235)\n","\n","Validation BLEU 10000: 26.87\n","Saved model: 10000 | BLEU 26.87\n","145185.7636270523 81303\n","Epoch  3, 10100/1000000; acc:  61.84; ppl:   5.96; 499 tgt tok/s;   1524 s elapsed\n","145863.83152604103 82053\n","Epoch  3, 10200/1000000; acc:  61.91; ppl:   5.92; 2147 tgt tok/s;   1562 s elapsed\n","148149.8610329628 82613\n","Epoch  3, 10300/1000000; acc:  61.66; ppl:   6.01; 2134 tgt tok/s;   1600 s elapsed\n","146409.6242017746 81691\n","Epoch  3, 10400/1000000; acc:  62.05; ppl:   6.00; 2140 tgt tok/s;   1639 s elapsed\n","145761.82556676865 81390\n","Epoch  3, 10500/1000000; acc:  61.92; ppl:   5.99; 2143 tgt tok/s;   1677 s elapsed\n","146751.53957986832 82028\n","Epoch  3, 10600/1000000; acc:  62.13; ppl:   5.98; 2137 tgt tok/s;   1715 s elapsed\n","shuffle iwslt/train.en.bpe | iwslt/train.vi.bpe\n","86195.24879169464 48473\n","Epoch  4, 10700/1000000; acc:  61.90; ppl:   5.92; 2200 tgt tok/s;     22 s elapsed\n","142305.92467689514 81404\n","Epoch  4, 10800/1000000; acc:  62.63; ppl:   5.74; 2128 tgt tok/s;     60 s elapsed\n","141729.2684226036 81413\n","Epoch  4, 10900/1000000; acc:  62.62; ppl:   5.70; 2132 tgt tok/s;     98 s elapsed\n","145097.59697055817 82981\n","Epoch  4, 11000/1000000; acc:  62.46; ppl:   5.75; 2154 tgt tok/s;    137 s elapsed\n","shuffle iwslt/test2015.en.bpe | iwslt/test2015.vi.bpe\n","67002.93603515625 25351\n","67002.93603515625 25351\n","Validation perplexity 11000: 14.0554\n","Learning rate: 1.5625e-05\n","Reaching minimum learning rate. Stop training!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sKxL_QoGFFiv","colab_type":"text"},"source":["USE MODEL TO TRANSLATE\n","# **TRANSLATE: ENG-VN**"]},{"cell_type":"markdown","metadata":{"id":"byjFDbbrGWvc","colab_type":"text"},"source":["create input.txt containing source sentences in Vietnamse"]},{"cell_type":"code","metadata":{"id":"lmyBRYzCGV56","colab_type":"code","outputId":"163ffb24-2233-41b0-8e0a-38ef354ca185","executionInfo":{"status":"ok","timestamp":1578533985233,"user_tz":-420,"elapsed":1267,"user":{"displayName":"Thư Trần Thị Anh","photoUrl":"","userId":"06893536815286384763"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile input.txt\n","The boy sitting next to the girls ordered a coffee"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Overwriting input.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Imn8aLMkKkCN","colab_type":"text"},"source":["translate command"]},{"cell_type":"code","metadata":{"id":"XMcIrrrHB3ra","colab_type":"code","outputId":"d14ef905-794b-4bb8-8c4a-4c0be4ce914d","executionInfo":{"status":"ok","timestamp":1578534783699,"user_tz":-420,"elapsed":11149,"user":{"displayName":"Thư Trần Thị Anh","photoUrl":"","userId":"06893536815286384763"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["!python translate.py -checkpoint model_best.pt -input input.txt -gpuid 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["| train configuration\n","Namespace(batch_size=64, beam_size=12, datasets=['iwslt/train.en.bpe', 'iwslt/train.vi.bpe'], decoder_type='rnn', dicts=['iwslt/all.en.bpe.pkl', 'iwslt/all.vi.bpe.pkl'], dropout=0.3, encode_multi_key=True, encoder_type='sabrnn', epochs=13, eval_every=5000, gpuid=[0], hard=False, input_feed=1, layers=2, learning_rate=0.001, learning_rate_decay=0.5, max_decay_step=5, max_generator_batches=32, max_grad_norm=5, max_seq_length=100, max_thres=7.0, max_updates=1000000, min_thres=-5.0, optim='adam', param_init=0.1, report_every=100, rnn_size=256, rnn_type='LSTM', save_model='model', seed=42, share_attn=True, share_decoder_embeddings=True, shuffle=1, src_vocab_size=9973, start_checkpoint_at=0, start_epoch=1, start_eval_checkpoint_at=0, tgt_vocab_size=9759, train_from='model_best.pt', valid_datasets=['iwslt/test2015.en.bpe', 'iwslt/test2015.vi.bpe'], word_vec_size=256)\n","Loading model\n","MY OPT INPUT input.txt\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:37: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  volatile=True)\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  init_target = Variable(init_target, volatile=True)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/content/drive/My Drive/_Schoolings/CS418 - Introduction to Natural Language Processing/Final Present/Code/sa-nmt/infer.py:115: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  init_target = Variable(next_ys.view(1, -1), volatile=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zTn8u1OjGNMG","colab_type":"text"},"source":["VIEW TRANSLATE RESULT\n","# **VIEW TRANSLATION RESULT: ENG-VN**"]},{"cell_type":"code","metadata":{"id":"dlk7JQkCFV3a","colab_type":"code","colab":{}},"source":["%pycat trans.bpe"],"execution_count":0,"outputs":[]}]}